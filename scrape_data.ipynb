{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests # for making standard html requests\n",
    "from urllib.request import Request, urlopen\n",
    "from bs4 import BeautifulSoup as soup # magical tool for parsing html data\n",
    "import json # for parsing data\n",
    "import pandas as pd\n",
    "import csv\n",
    "import random\n",
    "import time\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "douglas 0 18\n",
      "douglas 20 38\n",
      "douglas 40 58\n",
      "ballincollig 0 74\n",
      "ballincollig 20 92\n",
      "ballincollig 40 92\n",
      "carrigaline 0 110\n",
      "carrigaline 20 130\n",
      "carrigaline 40 138\n",
      "bishopstown 0 157\n",
      "bishopstown 20 162\n",
      "bishopstown 40 162\n",
      "glasheen 0 177\n",
      "glasheen 20 177\n",
      "glasheen 40 177\n",
      "blackrock 0 196\n",
      "blackrock 20 201\n",
      "blackrock 40 201\n",
      "rochestown 0 221\n",
      "rochestown 20 223\n",
      "rochestown 40 223\n",
      "lehenaghmore 0 230\n",
      "lehenaghmore 20 230\n",
      "lehenaghmore 40 230\n",
      "ballinlough 0 238\n",
      "ballinlough 20 238\n",
      "ballinlough 40 238\n",
      "ballintemple 0 244\n",
      "ballintemple 20 244\n",
      "ballintemple 40 244\n",
      "wilton 0 250\n",
      "wilton 20 250\n",
      "wilton 40 250\n",
      "model-farm-road 0 262\n",
      "model-farm-road 20 262\n",
      "model-farm-road 40 262\n"
     ]
    }
   ],
   "source": [
    "# Build list of user agents to avoid being blocked.\n",
    "user_agents = [\"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:77.0) Gecko/20100101 Firefox/77.0\",\n",
    "               \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:77.0) Gecko/20100101 Firefox/77.0\",\n",
    "               \"Mozilla/5.0\"]\n",
    "containers = []\n",
    "\n",
    "# Pull 10 pages of listings for list of suburbs in Cork city area.\n",
    "for location in ['douglas','ballincollig','carrigaline','bishopstown','glasheen','blackrock','rochestown',\n",
    "                 'lehenaghmore','ballinlough','ballintemple','wilton','model-farm-road']:\n",
    "    for offset in range(0,60,20): # 20 listings per page\n",
    "        user_agent = random.sample(user_agents,1)\n",
    "        url = \"http://www.daft.ie/cork-city/houses-for-sale/\" + location + \"/?offset=\" + str(offset)\n",
    "        req = Request(url , headers={'User-Agent': str(user_agent)})\n",
    "        webpage = urlopen(req).read()\n",
    "        page_soup = soup(webpage, \"html.parser\")\n",
    "        containers += page_soup.findAll(\"div\",\"AdCard__adCardContainer AdCard__adCardContainer--premium\")\n",
    "        containers += page_soup.findAll(\"div\",\"AdCard__adCardContainer AdCard__adCardContainer--standard\")\n",
    "        time.sleep(5) # Wait 5 seconds between hitting site\n",
    "        print(location,offset, len(containers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ad Detected!\n",
      "New Listing\n",
      "Ad Detected!\n",
      "Ad Detected!\n",
      "New Listing\n",
      "Ad Detected!\n",
      "Ad Detected!\n",
      "New Listing\n",
      "Ad Detected!\n",
      "Ad Detected!\n",
      "New Listing\n"
     ]
    }
   ],
   "source": [
    "# For each kind of listing, create a list of containers.\n",
    "# containers = page_soup.findAll(\"div\",\"AdCard__adCardContainer AdCard__adCardContainer--premium\")\n",
    "# containers += page_soup.findAll(\"div\",\"AdCard__adCardContainer AdCard__adCardContainer--standard\")\n",
    "\n",
    "# Check all previous scrapes. If there is a new listing in this run then pull additional details from listing page\n",
    "df = pd.concat([pd.read_csv(f) for f in glob.glob('cork_property_prices*.csv')], ignore_index = True)\n",
    "df = df.drop_duplicates(subset='listing_id', keep='last') # Dedup on listing_id and keep first record.\n",
    "listings = set(df['listing_id'])\n",
    "\n",
    "# Write data to an array for output to csv later\n",
    "rows = []\n",
    "\n",
    "for idx, container in enumerate(containers):\n",
    "    listing = {}\n",
    "    # Check if the listing is \"valid\", ads will not have a price section.\n",
    "    if container.find('strong', \"PropertyInformationCommonStyles__costAmountCopy\") is None:\n",
    "        print(\"Ad Detected!\")\n",
    "    else: \n",
    "        listing['listing_id'] = container.find('a',\"PropertyInformationCommonStyles__addressCopy--link\")[\"href\"].split(\"-\")[-1][:-1]\n",
    "        listing['url'] = container.find('a',\"PropertyInformationCommonStyles__addressCopy--link\")[\"href\"]\n",
    "        listing['location'] = container.find('a',\"PropertyInformationCommonStyles__propertyPrice--link\")[\"href\"].split(\"/\")[3]\n",
    "        listing['address'] = container.find('a',\"PropertyInformationCommonStyles__addressCopy--link\").getText().replace(\",\",\"|\")\n",
    "        listing['beds'] = container.find('div', \"QuickPropertyDetails__iconCopy\").getText()\n",
    "        listing['bathrooms'] = container.find('div', \"QuickPropertyDetails__iconCopy--WithBorder\").getText()\n",
    "        listing['cost'] = container.find('strong', \"PropertyInformationCommonStyles__costAmountCopy\").getText().replace(\"â‚¬\",\"\")\n",
    "        listing['num_pics'] = container.find('span', \"PropertyImage__picturesAmountCopy\").getText()\n",
    "        listing['property_type'] = container.find('div', \"QuickPropertyDetails__propertyType\").getText().replace(\"\\n\",\"\").strip()\n",
    "        try:\n",
    "            listing['ber'] = container.find(\"img\",{\"class\":\"PropertyImage__berImage\"}).get_attribute_list(\"src\")[0][-6:-4]\n",
    "        except:\n",
    "            listing['ber'] = 'NA'\n",
    "        rows.append(list(listing.values())) # Add listing to rows list for output.\n",
    "        \n",
    "        if int(listing['listing_id']) not in listings:\n",
    "            eircode = page_soup.find('div', \"PropertyMainInformation__eircode\").getText().split(\":\")[1].strip()\n",
    "            propertyOverviewDetails = page_soup.find('div', \"PropertyOverview__propertyOverviewDetails\").getText()\n",
    "            if \"Overall Floor Area\" in propertyOverviewDetails:\n",
    "                floor_area = propertyOverviewDetails.split(\"Overall Floor Area:\")[1].strip().split(\" \")[0]\n",
    "        else:\n",
    "            # Old listing\n",
    "            listing['eircode'] = \"\"\n",
    "            listing['floor_area'] = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.daft.ie//cork/houses-for-sale/douglas/1-well-road-homes-churchyard-lane-douglas-cork-2600677/\n",
      "74.3\n",
      "http://www.daft.ie//cork/houses-for-sale/ballincollig/46-tuairin-glas-greenfield-ballincollig-cork-2600311/\n",
      "http://www.daft.ie//cork/houses-for-sale/bishopstown/maryville-48-rossa-avenue-bishopstown-cork-2419284/\n",
      "158.18\n",
      "http://www.daft.ie//cork/houses-for-sale/cork-city/54-wilton-road-cork-city-cork-2544464/\n",
      "109\n"
     ]
    }
   ],
   "source": [
    "# Check all previous scrapes. If there is a new listing in this run then pull additional details from the page of that listing\n",
    "df = pd.concat([pd.read_csv(f) for f in glob.glob('cork_property_prices*.csv')], ignore_index = True)\n",
    "df = df.drop_duplicates(subset='listing_id', keep='last') # Dedup on listing_id and keep first record.\n",
    "listings = set(df['listing_id'])\n",
    "\n",
    "for row in rows: \n",
    "    if int(row[0]) not in listings:\n",
    "        url = \"http://www.daft.ie/\" + row[1]\n",
    "        print(url)\n",
    "        req = Request(url , headers={'User-Agent': str(user_agent)})\n",
    "        webpage = urlopen(req).read()\n",
    "        page_soup = soup(webpage, \"html.parser\")\n",
    "        eircode = page_soup.find('div', \"PropertyMainInformation__eircode\").getText().split(\":\")[1].strip()\n",
    "        propertyOverviewDetails = page_soup.find('div', \"PropertyOverview__propertyOverviewDetails\").getText()\n",
    "        if \"Overall Floor Area\" in propertyOverviewDetails:\n",
    "            floor_area = propertyOverviewDetails.split(\"Overall Floor Area:\")[1].strip().split(\" \")[0]\n",
    "            print(floor_area)\n",
    "        time.sleep(5)\n",
    "        floor = float(floor_area)\n",
    "# Get eircode <div class=\"PropertyMainInformation__eircode\">\n",
    "# Get floor area <span class=\"PropertyOverview__floorArea\">Overall Floor Area:</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Output to flat file for modeling \n",
    "#filename = \"cork_property_prices.csv\"\n",
    "filename = \"cork_property_prices_\" + str(round(time.time())) + \".csv\"\n",
    "\n",
    "# field names  \n",
    "fields = ['listing_id', 'url', 'location', 'address', 'beds', 'bathrooms', 'cost', 'num_pics', 'property_type', 'ber'] \n",
    "\n",
    "# writing to csv file  \n",
    "with open(filename, 'w') as csvfile:  \n",
    "    # creating a csv writer object  \n",
    "    csvwriter = csv.writer(csvfile)  \n",
    "        \n",
    "    # writing the fields  \n",
    "    csvwriter.writerow(fields)  \n",
    "        \n",
    "    # writing the data rows  \n",
    "    csvwriter.writerows(rows) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
